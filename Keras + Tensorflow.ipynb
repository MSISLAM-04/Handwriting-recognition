{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras + Tensorflow MNIST\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we implement a Convolutional Neural Network (CNN) model with Keras using the TensorFlow backend. We use the dataset from the Digit Recognizer competition of Kaggle (see [here](https://www.kaggle.com/c/digit-recognizer)).\n",
    "\n",
    "We will use a VGG-like architecture for our neural network, this is, it will consist of a series of convolutional, followed by fully connected layers. We will also add pooling and dropout layers to decrease the number of parameters and to regularize the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "We start by importing the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import toimage\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the dataset into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\", encoding = 'ISO-8859-1')\n",
    "df_subm =  pd.read_csv(\"test.csv\", encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check that there is no missing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum().sum() , df_subm.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is in fact, no missing data. We now take a look at the dataframes to see their structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 784 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_subm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training data consists of 785 columns, from which the first one corresponds to the label of the digit, and the other 784 correspond to all the 28x28 pixels composing each image. The submission dataframe does not contain the label, as expected. We proceed to extract the labels from the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[df_train.columns[1:]]\n",
    "y_train = df_train['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use the train_test_split tool from sklearn to separate our training data into two batches: one that we will use to train our neural network, and one that we will use to evaluate the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the to_categorical tool from Keras to one-hot-encode the labels of our dataset. This is, for each possible value of the labels, we create a column, and the column corresponding to the label has a 1, while the others have a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the dataset has the appropriate format, we can have a look at how the images look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0, 9):\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow((X_train.iloc[i].values.reshape(28,28)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we convert the dataframe into a 4 dimensional tensor. The first dimension runs through the set of examples, the second and third correspond to the two dimensions of the image and the fourth dimension correspond to the each channel of the picture (for RGB images we need three channels while for grayscale we only need one channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.values.reshape(X_train.shape[0],28,28,1)\n",
    "X_test = X_test.values.reshape(X_test.shape[0],28,28,1)\n",
    "# X_train = X_train.values.reshape(df_train.shape[0],28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute now the range of values that the data takes, so we can properly normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.max() - X_train.min() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can normalize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255\n",
    "X_test = X_test/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to build our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN: the sequential model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras makes the construction of deep neural networks much easier than Tensorflow. For this, we just need to build a sequential model, and add each layer sequentially (as the name suggests), keeping in mind that the dimensions of the output of each layer must coincide with the dimensions of the input of the next layer. \n",
    "\n",
    "The architecture of the CNN is based on the VGG-like convolutional neural network provided by the Keras documentation (see [here](https://keras.io/getting-started/sequential-model-guide/#examples)).\n",
    "\n",
    "We start by building the sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add two groups of layers consisting of convolutions, maxpooling and dropout layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We follow this by two fully connected (dense) layers, with another dropout layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This finishes the architecture of the CNN. Now we choose an optimizer to train the model. We choose Stochastic Gradient Descent (SGD) with decay, momentum and Nesterov momentum for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we compile the model. We will use the categorical cross entropy as a loss function, and we will measure scores with the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print a summary of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 10, 10, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 329,962\n",
      "Trainable params: 329,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ready to train the model. We have commented this line as we will use a slightly modified version of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(X_train, y_train, batch_size=128, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compute the score of the model on the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this model, we can obtain scores of around 0.988 on the submission data. We can improve this to get even higher scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "In this section, we perform what is called Data Augmentation. This procedure consists of generating more data with our available dataset. The way we do this is by applying several transformations to our dataset. This is a widely used technique. For this, we will use the ImageDataGenerator tool from Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by building the object that will randomly generate such transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the parameters indicate that the pictures will be rotated in a random angle between -10,10 degrees, and a vertical and horizontal shift will be applied. In this way, we will count with a much more diverse dataset which will allow our model to learn better parameters for predicting in test datasets. We now fit the data generator to our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we generate the data and fit the model with the augmented data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "246/246 [==============================] - 58s 235ms/step - loss: 1.2945 - acc: 0.5500\n",
      "Epoch 2/30\n",
      "246/246 [==============================] - 50s 203ms/step - loss: 0.3915 - acc: 0.8752\n",
      "Epoch 3/30\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 0.2606 - acc: 0.9193\n",
      "Epoch 4/30\n",
      "246/246 [==============================] - 51s 208ms/step - loss: 0.2080 - acc: 0.9364\n",
      "Epoch 5/30\n",
      "246/246 [==============================] - 51s 206ms/step - loss: 0.1811 - acc: 0.9434\n",
      "Epoch 6/30\n",
      "246/246 [==============================] - 50s 205ms/step - loss: 0.1535 - acc: 0.9524\n",
      "Epoch 7/30\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 0.1361 - acc: 0.9588\n",
      "Epoch 8/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.1309 - acc: 0.9604\n",
      "Epoch 9/30\n",
      "246/246 [==============================] - 50s 203ms/step - loss: 0.1212 - acc: 0.9627\n",
      "Epoch 10/30\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 0.1149 - acc: 0.9647\n",
      "Epoch 11/30\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 0.1052 - acc: 0.9687\n",
      "Epoch 12/30\n",
      "246/246 [==============================] - 49s 200ms/step - loss: 0.0935 - acc: 0.9713\n",
      "Epoch 13/30\n",
      "246/246 [==============================] - 50s 201ms/step - loss: 0.0916 - acc: 0.9716\n",
      "Epoch 14/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.0909 - acc: 0.9730\n",
      "Epoch 15/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.0826 - acc: 0.97501s - loss: 0.0824 - acc: 0\n",
      "Epoch 16/30\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 0.0860 - acc: 0.9728\n",
      "Epoch 17/30\n",
      "246/246 [==============================] - 49s 197ms/step - loss: 0.0825 - acc: 0.9749\n",
      "Epoch 18/30\n",
      "246/246 [==============================] - 50s 202ms/step - loss: 0.0814 - acc: 0.9759\n",
      "Epoch 19/30\n",
      "246/246 [==============================] - 49s 200ms/step - loss: 0.0761 - acc: 0.9766\n",
      "Epoch 20/30\n",
      "246/246 [==============================] - 49s 200ms/step - loss: 0.0744 - acc: 0.9780\n",
      "Epoch 21/30\n",
      "246/246 [==============================] - 48s 197ms/step - loss: 0.0715 - acc: 0.9770\n",
      "Epoch 22/30\n",
      "246/246 [==============================] - 48s 196ms/step - loss: 0.0699 - acc: 0.9796\n",
      "Epoch 23/30\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 0.0673 - acc: 0.9797\n",
      "Epoch 24/30\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 0.0671 - acc: 0.9796\n",
      "Epoch 25/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.0633 - acc: 0.9808\n",
      "Epoch 26/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.0582 - acc: 0.9818\n",
      "Epoch 27/30\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 0.0594 - acc: 0.9822\n",
      "Epoch 28/30\n",
      "246/246 [==============================] - 49s 198ms/step - loss: 0.0612 - acc: 0.9824\n",
      "Epoch 29/30\n",
      "246/246 [==============================] - 49s 201ms/step - loss: 0.0553 - acc: 0.9826\n",
      "Epoch 30/30\n",
      "246/246 [==============================] - 49s 199ms/step - loss: 0.0599 - acc: 0.98120s - loss: 0.0598 - acc: 0.98\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xfd95710>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n",
    "                    steps_per_epoch=int(len(X_train) / 128), epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we evaluate the model on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10500/10500 [==============================] - 5s 520us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.019060105884366966, 0.9941904761904762]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how is the model performing with the confusion matrix tool of Sklearn. This will show which numbers are being mislabeled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1062,    0,    1,    0,    1,    0,    1,    0,    0,    0],\n",
       "       [   0, 1225,    2,    0,    0,    0,    0,    1,    0,    0],\n",
       "       [   0,    1, 1002,    3,    0,    0,    0,    1,    2,    0],\n",
       "       [   0,    0,    1, 1044,    0,    3,    0,    1,    2,    1],\n",
       "       [   0,    1,    0,    0, 1002,    0,    0,    0,    0,    4],\n",
       "       [   0,    0,    0,    2,    0,  965,    2,    0,    1,    0],\n",
       "       [   0,    0,    0,    0,    0,    1,  992,    0,    0,    0],\n",
       "       [   0,    1,    4,    0,    1,    0,    0, 1107,    0,    4],\n",
       "       [   1,    0,    0,    0,    1,    2,    1,    1,  988,    3],\n",
       "       [   1,    0,    0,    0,    6,    0,    0,    0,    3, 1052]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(np.argmax(y_test,axis=1,out=None),np.argmax(model.predict(X_test), axis=1, out=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the major source of errors are 4's being labeled as 9 and vice versa. This is mostly due to how some people draw these numbers in a very similar way. Finally, we can measure the accuracy of the model with the Sklearn accuracy tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941904761904762"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(y_test,axis=1,out=None),np.argmax(model.predict(X_test), axis=1, out=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission \n",
    "\n",
    "Now we can proceed to generate the submission data. For this, we will use the same formatting as we used in the first part of the kernel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We put the values of the submission data in a matrix\n",
    "test_data = df_subm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We reshape the matrix as a 4 dimensional tensor\n",
    "test_data = test_data.reshape(test_data.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We normalize the data with the same factor as we did for the train data\n",
    "test_data = test_data/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use the model to generate the predictions\n",
    "predictions = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We get the labels of the predictions, recalling that we used a one-hot-encoding \n",
    "#to train the model\n",
    "predictions = np.argmax(predictions, axis=1, out=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We generate a csv file with the predictions in the required format\n",
    "with open(\"resultCNNwithPrepros.csv\", \"wb\") as f:\n",
    "    f.write(b'ImageId,Label\\n')\n",
    "    np.savetxt(f, np.hstack([(np.array(range(28000))+1).reshape(-1,1), predictions.astype(int).reshape(-1,1)]), fmt='%i', delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This concludes this kernel. We believe that there is still room for improvement, either by optimizing over the architecture of the model or the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
